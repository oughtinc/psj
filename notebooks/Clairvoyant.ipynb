{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from datetime import datetime\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "from definitions import HUMAN_DATA_DIR, ROOT_DIR\n",
    "from data.load_from_csv import get_content_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClairvoyantCF(test_dataset, train_dataset, answers_dict):\n",
    "    \"\"\"Takes datasets and {item_id: True/False} dict and returns\n",
    "    mean mse simply predicting 0/100\"\"\"\n",
    "    total_score = 0\n",
    "    for i, rating in enumerate(test_dataset.ratings):\n",
    "        try:\n",
    "            if answers_dict[test_dataset.item_ids[i]]:\n",
    "                total_score += (rating[2] - 1.0)**2\n",
    "            else:\n",
    "                total_score += (rating[2] - 0)**2\n",
    "        except:\n",
    "            print(i, test_dataset.item_ids[i])\n",
    "    mean_mse = total_score / len(test_dataset.ratings)\n",
    "    print(\"Using Clairvoyant CF, got total val score {:.3f}\".format(mean_mse))\n",
    "    return\n",
    "\n",
    "def ClairvoyantAdjustedCF(test_dataset, train_dataset, answers_dict):\n",
    "    \"\"\"Takes datasets and {item_id: True/False} dict and returns\n",
    "    mean mse simply predicting 0/100\"\"\"\n",
    "    tot_true = 0\n",
    "    tot_false = 0\n",
    "    true_count = 0\n",
    "    false_count = 0\n",
    "    \n",
    "    for i, rating in enumerate(train_dataset.ratings):\n",
    "        if not np.isnan(rating[2]):\n",
    "            if answers_dict[train_dataset.item_ids[i]]:\n",
    "                tot_true += rating[2]\n",
    "                true_count += 1\n",
    "            else:\n",
    "                tot_false += rating[2]\n",
    "                false_count += 1            \n",
    "    avg_true = tot_true / true_count\n",
    "    avg_false = tot_false / false_count\n",
    "    \n",
    "    total_score = 0\n",
    "    for i, rating in enumerate(test_dataset.ratings):\n",
    "        if answers_dict[test_dataset.item_ids[i]]:\n",
    "            total_score += (rating[2] - avg_true)**2\n",
    "        else:\n",
    "            total_score += (rating[2] - avg_false)**2\n",
    "    mean_mse = total_score / len(test_dataset.ratings)\n",
    "    print(\"Using Clairvoyant Adjusted CF, got total val score {:.3f}\".format(mean_mse))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fermi_answers = pd.read_csv(os.path.join(HUMAN_DATA_DIR, 'fermi', 'answers.csv')).drop('Unnamed: 0', axis=1).set_index('item_id').T.to_dict('index')['answer']\n",
    "politifact_answers = pd.read_csv(os.path.join(HUMAN_DATA_DIR, 'politifact', 'answers.csv')).drop('Unnamed: 0', axis=1).set_index('item_id').T.to_dict('index')['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fermi\n",
      "Unmasked:\n",
      "Using Clairvoyant CF, got total val score 0.216\n",
      "Using Clairvoyant Adjusted CF, got total val score 0.111\n",
      "\n",
      "Light Masking:\n",
      "Using Clairvoyant CF, got total val score 0.216\n",
      "Using Clairvoyant Adjusted CF, got total val score 0.111\n",
      "\n",
      "Heavy Masking:\n",
      "Using Clairvoyant CF, got total val score 0.216\n",
      "Using Clairvoyant Adjusted CF, got total val score 0.111\n"
     ]
    }
   ],
   "source": [
    "## Fermi \n",
    "print('Fermi\\nUnmasked:')\n",
    "unmasked_fermi, unmasked_val_fermi, _ = get_content_datasets(task='fermi', sparsity='unmasked')\n",
    "ClairvoyantCF(unmasked_val_fermi, unmasked_fermi, fermi_answers)\n",
    "ClairvoyantAdjustedCF(unmasked_val_fermi, unmasked_fermi, fermi_answers)\n",
    "print('\\nLight Masking:')\n",
    "light_fermi, unmasked_val_fermi, _ = get_content_datasets(task='fermi', sparsity='light')\n",
    "ClairvoyantCF(unmasked_val_fermi, light_fermi, fermi_answers)\n",
    "ClairvoyantAdjustedCF(unmasked_val_fermi, light_fermi, fermi_answers)\n",
    "print('\\nHeavy Masking:')\n",
    "heavy_fermi, unmasked_val_fermi, _ = get_content_datasets(task='fermi', sparsity='heavy')\n",
    "ClairvoyantCF(unmasked_val_fermi, heavy_fermi, fermi_answers)\n",
    "ClairvoyantAdjustedCF(unmasked_val_fermi, heavy_fermi, fermi_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politifact\n",
      "Unmasked:\n",
      "Loading w2v dict\n",
      "Loaded Word2Vec dict: 27.13s\n",
      "Number of words in corpus: 400001\n",
      "Using Clairvoyant CF, got total val score 0.242\n",
      "Using Clairvoyant Adjusted CF, got total val score 0.112\n",
      "\n",
      "Politifact Masking:\n",
      "Loading w2v dict\n",
      "Loaded Word2Vec dict: 23.40s\n",
      "Number of words in corpus: 400001\n",
      "Using Clairvoyant CF, got total val score 0.242\n",
      "Using Clairvoyant Adjusted CF, got total val score 0.112\n",
      "\n",
      "Politifact Masking:\n",
      "Loading w2v dict\n",
      "Loaded Word2Vec dict: 18.82s\n",
      "Number of words in corpus: 400001\n",
      "Using Clairvoyant CF, got total val score 0.242\n",
      "Using Clairvoyant Adjusted CF, got total val score 0.112\n"
     ]
    }
   ],
   "source": [
    "## Politifact\n",
    "print('Politifact\\nUnmasked:')\n",
    "unmasked_politifact, unmasked_val_politifact, _ = get_content_datasets(task='politifact', sparsity='unmasked')\n",
    "ClairvoyantCF(unmasked_val_politifact, unmasked_politifact, politifact_answers)\n",
    "ClairvoyantAdjustedCF(unmasked_val_politifact, unmasked_politifact, politifact_answers)\n",
    "print('\\nPolitifact Masking:')\n",
    "light_politifact, unmasked_val_politifact, _ = get_content_datasets(task='politifact', sparsity='light')\n",
    "ClairvoyantCF(unmasked_val_politifact, light_politifact, politifact_answers)\n",
    "ClairvoyantAdjustedCF(unmasked_val_politifact, light_politifact, politifact_answers)\n",
    "print('\\nPolitifact Masking:')\n",
    "heavy_politifact, unmasked_val_politifact, _ = get_content_datasets(task='politifact', sparsity='heavy')\n",
    "ClairvoyantCF(unmasked_val_politifact, heavy_politifact, politifact_answers)\n",
    "ClairvoyantAdjustedCF(unmasked_val_politifact, heavy_politifact, politifact_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
